{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10fold crossvalidation 10fold crossvalidation ['10fold cross validation']\n",
      "2011 wiley periodicals 2011 wiley periodical ['2010 wiley periodical']\n",
      "2012 wiley periodicals 2012 wiley periodical ['2010 wiley periodical']\n",
      "adhoc network adhoc network ['ad hoc network']\n",
      "adhoc networks adhoc network ['ad hoc network']\n",
      "adhoc retrieval adhoc retrieval ['ad hoc retrieval']\n",
      "aluminum aluminum ['aluminium']\n",
      "approximation algorithm approximation algorithm ['2approximation algorithm']\n",
      "approximation algorithms approximation algorithm ['2approximation algorithm']\n",
      "artificial datasets artificial dataset ['artificial data set']\n",
      "association rules mining association rules mining ['association rule mining']\n",
      "benchmark dataset benchmark dataset ['benchmark data set']\n",
      "benchmark datasets benchmark dataset ['benchmark data set']\n",
      "biterror rate biterror rate ['bit error rate']\n",
      "boolean formulae boolean formulae ['boolean formula']\n",
      "boxing boxing ['boeing']\n",
      "brain tumour brain tumour ['brain tumor']\n",
      "braincomputer interface braincomputer interface ['brain computer interface']\n",
      "braincomputer interfaces braincomputer interface ['brain computer interface']\n",
      "breadthfirst search breadthfirst search ['breadth first search']\n",
      "casebased reasoning casebased reasoning ['case based reasoning']\n",
      "catalyst catalyst ['catalysi']\n",
      "cell nucleus cell nucleu ['cell nuclei']\n",
      "client/server client/server ['client server']\n",
      "closedform expression closedform expression ['closed form expression']\n",
      "closedform expressions closedform expression ['closed form expression']\n",
      "codedivision multiple access codedivision multiple access ['code division multiple access']\n",
      "collagen collagen ['collage']\n",
      "color/texture color/texture ['color texture']\n",
      "colour constancy colour constancy ['color constancy']\n",
      "colour images colour image ['color image']\n",
      "communications protocol communications protocol ['communication protocol']\n",
      "computeraided design computeraided design ['computer aided design']\n",
      "conceptual modelling conceptual modelling ['conceptual modeling']\n",
      "conditional independencies conditional independency ['conditional independence']\n",
      "contentbased image retrieval contentbased image retrieval ['content based image retrieval']\n",
      "contextfree grammar contextfree grammar ['context free grammar']\n",
      "contextfree grammars contextfree grammar ['context free grammar']\n",
      "cytosine cytosine ['cytokine']\n",
      "data cleansing data cleansing ['data cleaning']\n",
      "database management database management ['data base management']\n",
      "datatype datatype ['data type']\n",
      "depthfirst search depthfirst search ['depth first search']\n",
      "dna microarray dna microarray ['cdna microarray']\n",
      "dna microarrays dna microarray ['cdna microarray']\n",
      "drought drought ['draught']\n",
      "earley earley ['barley']\n",
      "eeg signal eeg signal ['ecg signal']\n",
      "eeg signals eeg signal ['ecg signal']\n",
      "errorcorrecting codes errorcorrecting code ['error correcting code']\n",
      "feedforward neural network feedforward neural network ['feed forward neural network']\n",
      "feedforward neural networks feedforward neural network ['feed forward neural network']\n",
      "fieldprogrammable gate fieldprogrammable gate ['field programmable gate']\n",
      "finitestate automata finitestate automatum ['finite state automatum']\n",
      "fixedparameter tractable fixedparameter tractable ['fixed parameter tractable']\n",
      "fluorescence microscopy fluorescence microscopy ['fluorescence microscope']\n",
      "frequencyselective channels frequencyselective channel ['frequency selective channel']\n",
      "frequent itemset frequent itemset ['frequent item set']\n",
      "frequent itemsets frequent itemset ['frequent item set']\n",
      "gene expression dataset gene expression dataset ['gene expression data set']\n",
      "gene expression datasets gene expression dataset ['gene expression data set']\n",
      "geneexpression data geneexpression datum ['gene expression datum']\n",
      "genetic programming genetic programming ['generic programming']\n",
      "graffito graffito ['graffiti']\n",
      "grain size grain size ['brain size']\n",
      "grayscale image grayscale image ['gray scale image']\n",
      "grayscale images grayscale image ['gray scale image']\n",
      "grey level grey level ['gray level']\n",
      "grey matter grey matter ['gray matter']\n",
      "hard drives hard drife ['hard drive']\n",
      "hastings hasting ['fasting']\n",
      "hemoglobin hemoglobin ['haemoglobin']\n",
      "highdimensional data highdimensional datum ['high dimensional datum']\n",
      "highdimensional datasets highdimensional dataset ['highdimensional data set']\n",
      "highdimensional feature space highdimensional feature space ['high dimensional feature space']\n",
      "highdimensional space highdimensional space ['high dimensional space']\n",
      "highdimensional spaces highdimensional space ['high dimensional space']\n",
      "higherorder logic higherorder logic ['higher order logic']\n",
      "highperformance computing highperformance computing ['high performance computing']\n",
      "histones histone ['histon']\n",
      "hit rate hit rate ['bit rate']\n",
      "honeybee honeybee ['honey bee']\n",
      "honeybees honeybee ['honey bee']\n",
      "human behaviour human behaviour ['human behavior']\n",
      "imbalanced datasets imbalanced dataset ['imbalanced data set']\n",
      "initial state initial state ['initial stage']\n",
      "initial states initial state ['initial stage']\n",
      "input/output input/output ['input output']\n",
      "jasper jasper ['casper']\n",
      "jester jester ['ester']\n",
      "jobshop scheduling jobshop scheduling ['job shop scheduling']\n",
      "kmeans clustering kmeans clustering ['cmeans clustering', 'k means clustering']\n",
      "knearest neighbour knearest neighbour ['knearest neighbor']\n",
      "knowledgebased systems knowledgebased system ['knowledge based system']\n",
      "kuwaiti kuwaiti ['kuwait']\n",
      "l2 norm l2 norm ['l1 norm']\n",
      "large datasets large dataset ['large data set']\n",
      "layer 3 layer 3 ['layer 2']\n",
      "lisbon lisbon ['lisboa']\n",
      "locationbased services locationbased service ['location based service']\n",
      "longterm memory longterm memory ['long term memory']\n",
      "longwave longwave ['long wave']\n",
      "lowdimensional space lowdimensional space ['low dimensional space']\n",
      "lowpass filter lowpass filter ['low pass filter']\n",
      "meansquared error meansquared error ['meansquare error']\n",
      "medialtemporal lobe medialtemporal lobe ['medial temporal lobe']\n",
      "microarray data microarray datum ['micro array datum']\n",
      "microarray datasets microarray dataset ['microarray data set']\n",
      "minimum mean squared error minimum mean squared error ['minimum mean square error']\n",
      "minimum meansquare error minimum meansquare error ['minimum mean square error']\n",
      "minimumweight minimumweight ['minimum weight']\n",
      "mobile adhoc networks mobile adhoc network ['mobile ad hoc network']\n",
      "mobile telephony mobile telephony ['mobile telephone']\n",
      "modelling language modelling language ['modeling language']\n",
      "mrf model mrf model ['crf model']\n",
      "multiagent systems multiagent system ['multi agent system']\n",
      "multilayer perceptron multilayer perceptron ['multi layer perceptron']\n",
      "multilayer perceptrons multilayer perceptron ['multi layer perceptron']\n",
      "multipleaccess interference multipleaccess interference ['multiple access interference']\n",
      "multipleinstance learning multipleinstance learning ['multiple instance learning']\n",
      "naive bayes classifier naive bayes classifier ['na ve bayes classifier']\n",
      "naive bayes classifiers naive bayes classifier ['na ve bayes classifier']\n",
      "nakagamim fading nakagamim fading ['nakagami fading']\n",
      "ndimensional space ndimensional space ['dimensional space']\n",
      "nearest neighbor nearest neighbor ['knearest neighbor']\n",
      "nearest neighbor classifier nearest neighbor classifier ['knearest neighbor classifier']\n",
      "nearest neighbors nearest neighbor ['knearest neighbor']\n",
      "noncoding rna noncoding rna ['noncoding dna']\n",
      "noncoding rnas noncoding rna ['noncoding dna']\n",
      "objectoriented database objectoriented database ['object oriented database']\n",
      "objectoriented databases objectoriented database ['object oriented database']\n",
      "objectoriented programming objectoriented programming ['object oriented programming']\n",
      "opengl opengl ['opencl']\n",
      "opensource software opensource software ['open source software']\n",
      "optimization problem optimization problem ['optimisation problem']\n",
      "optimization problems optimization problem ['optimisation problem']\n",
      "oracle database 11g oracle database 11g ['oracle database 10g']\n",
      "orthogonal frequencydivision orthogonal frequencydivision ['orthogonal frequency division']\n",
      "orthogonal frequencydivision multiplexing orthogonal frequencydivision multiplexing ['orthogonal frequency division multiplexing']\n",
      "particle swarm optimization particle swarm optimization ['particle swarm optimisation']\n",
      "phaseshift keying phaseshift keying ['phase shift keying']\n",
      "pid controller pid controller ['pi controller']\n",
      "polymerization polymerization ['polymerisation']\n",
      "pottery pottery ['lottery']\n",
      "power levels power level ['lower level']\n",
      "principal components analysis principal components analysis ['principal component analysis']\n",
      "privacypreserving data mining privacypreserving data mining ['privacy preserving data mining']\n",
      "process calculus process calculu ['process calculi']\n",
      "protozoan protozoan ['protozoa']\n",
      "pseudorelevance feedback pseudorelevance feedback ['pseudo relevance feedback']\n",
      "radio waves radio wafe ['radio wave']\n",
      "radiofrequency radiofrequency ['radio frequency']\n",
      "rangefinder rangefinder ['range finder']\n",
      "real line real line ['real life']\n",
      "real world datasets real world dataset ['real world data set']\n",
      "reallife datasets reallife dataset ['reallife data set']\n",
      "realworld data sets realworld data set ['real world data set']\n",
      "realworld problems realworld problem ['real world problem']\n",
      "recession recession ['precession']\n",
      "relevance judgments relevance judgment ['relevance judgement']\n",
      "retroviruses retroviruse ['retrovirus']\n",
      "rician fading rician fading ['ricean fading']\n",
      "rna sequence rna sequence ['dna sequence']\n",
      "rna sequences rna sequence ['dna sequence']\n",
      "rolebased access control rolebased access control ['role based access control']\n",
      "rough sets theory rough sets theory ['rough set theory']\n",
      "rule based rule based ['rule base']\n",
      "selforganizing map selforganizing map ['selforganising map']\n",
      "selforganizing maps selforganizing map ['selforganising map']\n",
      "serviceoriented architecture serviceoriented architecture ['service oriented architecture']\n",
      "shortterm memory shortterm memory ['short term memory']\n",
      "singlenucleotide polymorphisms singlenucleotide polymorphism ['single nucleotide polymorphism']\n",
      "smartcard smartcard ['smart card']\n",
      "source node source node ['source code']\n",
      "source nodes source node ['source code']\n",
      "spacetime coded spacetime coded ['spacetime code']\n",
      "spiders spider ['slider']\n",
      "squared error squared error ['square error']\n",
      "statute statute ['statue']\n",
      "steroid steroid ['asteroid']\n",
      "structured prediction structured prediction ['structure prediction']\n",
      "sugarcane sugarcane ['sugar cane']\n",
      "swimmer swimmer ['shimmer']\n",
      "synthetic datasets synthetic dataset ['synthetic data set']\n",
      "text collection text collection ['test collection']\n",
      "text collections text collection ['test collection']\n",
      "text generation text generation ['test generation']\n",
      "theater theater ['cheater']\n",
      "timesharing timesharing ['time sharing']\n",
      "titanium titanium ['itanium']\n",
      "travelling salesman problem travelling salesman problem ['traveling salesman problem']\n",
      "tree structured tree structured ['tree structure']\n",
      "trellis codes trellis code ['trellis coded']\n",
      "type 2 diabetes type 2 diabete ['type 1 diabete']\n",
      "uci datasets uci dataset ['uci data set']\n",
      "unlabelled data unlabelled datum ['unlabeled datum']\n",
      "usergenerated content usergenerated content ['user generated content']\n",
      "vertebrae vertebrae ['vertebra']\n",
      "videoconferencing videoconferencing ['video conferencing']\n",
      "videogames videogame ['video game']\n",
      "visual stimulus visual stimulu ['visual stimuli']\n",
      "windows 98 windows 98 ['windows 95']\n",
      "xpath expressions xpath expression ['path expression']\n",
      "yield strength yield strength ['field strength']\n",
      "Number of entities between (potential) filtering = 12399\n",
      "Filtering entities with too small occurrences\n",
      "Number of filtered entities = 3997\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "__author__: Ellen Wu, Jiaming Shen, Dongming Lei\n",
    "__description__: Map entity surface to entity id and filter entities with too small occurrences.\n",
    "    Input: 1) entitylist (a list of raw entity mentions)\n",
    "    Output: 1) a map between entity surface name to eid and 2) a list of eid\n",
    "__latest_updates__: 08/23/2017\n",
    "'''\n",
    "from textblob import Word\n",
    "from collections import defaultdict\n",
    "import inflection\n",
    "import editdistance\n",
    "import sys\n",
    "\n",
    "EDIT_DISTANCE_THRESHOLD = 1\n",
    "\n",
    "def resolution(surfaceName, normalized_ename2eid):\n",
    "    '''\n",
    "    input: a surface name of entity\n",
    "    output: the \"normalized\" entity name\n",
    "    process: 1) lowercase\n",
    "             2) lemmatization\n",
    "    '''\n",
    "#     tmp = [Word(ele.lower()).lemmatize() for ele in surfaceName.split()]\n",
    "    \n",
    "    # tmp = [ele.lower() for ele in surfaceName.split()]\n",
    "#     return \" \".join(tmp)\n",
    "    tmp = surfaceName.lower()\n",
    "    tmp = tmp.replace('-', '')\n",
    "    tmp = tmp.replace('_', ' ')\n",
    "    \n",
    "    tmp = inflection.singularize(tmp)\n",
    "    \n",
    "    if tmp in normalized_ename2eid or len(tmp) <= 5:\n",
    "        return tmp\n",
    "    \n",
    "    # Step 2: Use edit distance to resolve \n",
    "    keys = normalized_ename2eid.keys()\n",
    "    existing_keys = [\n",
    "        ele for ele in normalized_ename2eid.keys() if editdistance.eval(tmp, ele) <= EDIT_DISTANCE_THRESHOLD\n",
    "    ]\n",
    "\n",
    "    if len(existing_keys) != 0:\n",
    "        print(surfaceName, tmp, existing_keys)\n",
    "        return existing_keys[0]\n",
    "    else:\n",
    "        return tmp\n",
    "    \n",
    "\n",
    "def main(corpusName, min_sup = -1):\n",
    "    data = corpusName\n",
    "    min_sup = int(min_sup)\n",
    "    inputFileName = '../../data/'+data+'/intermediate/entitylist.txt'\n",
    "    outputFileName = '../../data/'+data+'/intermediate/entity2id.txt'\n",
    "    uniqueEntityNameFileOut = '../../data/'+data+'/intermediate/eidlist.txt'\n",
    "\n",
    "    eid = 0\n",
    "    ename2eid = {}\n",
    "    normalized_ename2eid = {}\n",
    "    normalized_ename2freq = defaultdict(int)\n",
    "    with open(inputFileName,\"r\") as fin:\n",
    "        for line in fin:\n",
    "            segs = line.strip().split(\"\\t\")\n",
    "            ename = segs[0]\n",
    "            freq = int(segs[1])\n",
    "\n",
    "            normalized_ename = resolution(ename, normalized_ename2eid)\n",
    "            if normalized_ename in normalized_ename2eid: # already exist\n",
    "                ename2eid[ename] = normalized_ename2eid[normalized_ename]\n",
    "                normalized_ename2freq[normalized_ename] += freq\n",
    "            else: # a new entity\n",
    "                normalized_ename2eid[normalized_ename] = eid\n",
    "                normalized_ename2freq[normalized_ename] += freq\n",
    "                ename2eid[ename] = eid\n",
    "                eid += 1\n",
    "\n",
    "    print(\"Number of entities between (potential) filtering = %s\" % eid)\n",
    "    filtered_eid = set()\n",
    "    if min_sup != -1:\n",
    "        print(\"Filtering entities with too small occurrences\")\n",
    "        for ele in normalized_ename2freq.items():\n",
    "            if ele[1] < min_sup:\n",
    "                ## add the eid into the filtered set\n",
    "                filtered_eid.add(normalized_ename2eid[ele[0]])\n",
    "        print(\"Number of filtered entities = %s\" % len(filtered_eid))\n",
    "\n",
    "    with open(outputFileName,\"w\") as fout:\n",
    "        for ele in sorted(ename2eid.items(), key = lambda x:x[0]):\n",
    "            if ele[1] not in filtered_eid:\n",
    "                fout.write(ele[0]+\"\\t\"+str(ele[1])+\"\\n\")\n",
    "\n",
    "    with open(uniqueEntityNameFileOut,\"w\") as fout:\n",
    "        for ele in sorted(normalized_ename2eid.items(), key = lambda x:x[1] ):\n",
    "            if ele[1] not in filtered_eid:\n",
    "                fout.write(ele[0]+\"\\t\"+str(ele[1])+\"\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "#     corpusName = sys.argv[1]\n",
    "#     min_sup = sys.argv[2]\n",
    "    corpusName = 'dblp'\n",
    "    min_sup = 15\n",
    "    main(corpusName, min_sup)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the canonical form\n",
    "from collections import defaultdict\n",
    "\n",
    "data = 'dblpv2'\n",
    "\n",
    "entityCountFileName = '../../data/'+data+'/intermediate/entitylist.txt'\n",
    "entityCount = {}\n",
    "with open(entityCountFileName) as fin:\n",
    "    for line in fin:\n",
    "        segs = line.strip().split(\"\\t\")\n",
    "        entityCount[segs[0]] = int(segs[1])\n",
    "\n",
    "inputFileName = '../../data/'+data+'/intermediate/entity2id.txt'\n",
    "id2entities = defaultdict(set)\n",
    "with open(inputFileName) as fin:\n",
    "    for line in fin:\n",
    "        segs = line.strip().split(\"\\t\")\n",
    "        id2entities[segs[1]].add(segs[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "canonicalFormOutputFile = '../../data/'+data+'/intermediate/canonicalMapping.txt'\n",
    "with open(canonicalFormOutputFile, 'w') as fout:\n",
    "    for key, vals in id2entities.items():\n",
    "        vals = list(vals)\n",
    "        counts = [entityCount[ele] for ele in vals]\n",
    "        canonical_form = vals[np.argmax(counts)]\n",
    "        fout.write(canonical_form + '\\t' + ','.join(vals) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17065\n",
      "{'14102', '9502', '7180'}\n"
     ]
    }
   ],
   "source": [
    "embeddingFile = '../../data/'+data+'/intermediate/entity_word2vec.emb'\n",
    "\n",
    "print(len(id2entities))\n",
    "\n",
    "embedSet = set()\n",
    "with open(embeddingFile) as fin:\n",
    "    \n",
    "    for line in fin:\n",
    "        segs = line.strip().split(\" \")\n",
    "        embedSet.add(segs[0])\n",
    "\n",
    "print(set(id2entities.keys()) - embedSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
